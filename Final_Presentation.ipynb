{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZX1X5nNkOAZ"
   },
   "source": [
    "<h1><center> Final Presentation </center></h1> \n",
    "<h3><center> Autodiff-py development </center></h3> \n",
    "<center> Team Members: Ellie Han, Julien Laasri, Brian Lin, Bhaven Patel</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9j8-Vg4KXiCE"
   },
   "source": [
    "# Introduction /  Background\n",
    "\n",
    "<img src=\"ad.png\">\n",
    "\n",
    "\n",
    "Since Newton invented calculus, differentiating a function has been essential to the advancement of humanity. Calculating the derivative of a function is crucial to finding the extrema for a function and determining zeros for a function, two operations that are central to optimization (1). Often, we can find the symbolic/analytical solution to the derivative of a function, however this has become increasingly complex and computationally expensive as our functions/equations have grown in size and complexity. Numerically solving differential equations forms a cornerstone of modern science and engineering and is intimately linked with machine learning; however this method suffers from rounding errors and numerical instability. Many of these issues can be solved using Automatic Differentiation (AD) because AD can calculate the exact derivative up to machine precision (2). The logic and processes behind AD enables it to be implemented using computer code, making it easily accessible for use by scientists and mathematicians. This python package will implement the forward mode of AD. ​ ​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DOpLt-ih7_c"
   },
   "source": [
    "# Background\n",
    "​\n",
    "The following mathematical concepts and background are required for understanding automatic differentiation:\n",
    "​\n",
    "### 1. Differential calculus\n",
    "​\n",
    "Differential calculus is a subfield of calculus concerned with the study of the rates at which quantities change.\n",
    "For example, given the function: \n",
    "\\begin{align}\n",
    " f\\left(x\\right) &=  {x^{2}}     \n",
    " \\end{align}\n",
    " \n",
    " Increment x by h:\n",
    " \\begin{align}\n",
    " f\\left(x+h\\right) &=  {(x+h)^{2}}     \n",
    " \\end{align}\n",
    " \n",
    " Apply the finite difference approximation to calculate the slope:\n",
    "  \\begin{align}\n",
    " \\frac{f\\left(x+h\\right) - f\\left(x\\right) }{h}\n",
    " \\end{align}\n",
    " \n",
    "Simplify the equation:\n",
    "  \\begin{align}\n",
    " &= \\frac{x^{2}+2xh+h^{2}-x^{2} }{h}\\\\\n",
    " &= \\frac{2xh+h^{2}}{h}\\\\\n",
    " &=2x+h\n",
    " \\end{align}\n",
    " \n",
    " Set $h -> 0$:\n",
    "   \\begin{align}\n",
    " 2x +0 &= 2x\n",
    "  \\end{align}\n",
    "  \n",
    "The derivative is then defined is:\n",
    "\\begin{align}\n",
    " \\lim_{h\\to0} \\frac{f\\left(x+h\\right) - f\\left(x\\right) }{h}\n",
    " \\end{align}\n",
    " \n",
    "### 2. Elementary functions and their derivatives\n",
    "\n",
    "|       Function $f(x)$                |       Derivative $f^{\\prime}(x)$                |\n",
    "| :-------------------:  | :------------------------------------------------------------------------------:  |\n",
    "| ${c}$           | $0$         |\n",
    "| ${x}$           | $1$         |\n",
    "| ${x^{n}}$           | ${nx^{n-1}}$         |\n",
    "| $\\frac{1}{x}$     | $\\frac{-1}{x^{2}}$     |\n",
    "| $ln{x}$     | $\\frac{1}{x}$     |\n",
    "| $\\sin(x)$           |   $\\cos(x)$         |\n",
    "| $\\cos(x)$           |   $-\\sin(x)$         |\n",
    "| $\\tan(x)$           |   $\\dfrac{1}{\\cos^2(x)}$         |\n",
    "| $\\exp(x)$           |   $\\exp(x)$         |\n",
    "| ${a^{x}}$           |   ${a^{x}\\ln{a}}$         |\n",
    " \n",
    "### 3. The chain rule$^{(1)}$\n",
    "\n",
    "For a function $h(u(t))$, the derivative of $h$ with respect to $t$ can be expressed as:\n",
    "$$\\dfrac{\\partial h}{\\partial t} = \\dfrac{\\partial h}{\\partial u}\\dfrac{\\partial u}{\\partial t}.$$\n",
    "If the function is expressed as a combination of multiple variables that are expressed in terms of t, i.e. $h(u(t), v(t))$, the the derivative of $h$ with respect to $t$ can be expressed as:\n",
    "$$\\frac{\\partial h}{\\partial t} = \\frac{\\partial h}{\\partial u}\\frac{\\partial u}{\\partial t} + \\frac{\\partial h}{\\partial v}\\frac{\\partial v}{\\partial t}$$\n",
    "\n",
    "Note that we are only looking at scalar variables in this case, but this idea can be extended to vector variables as well.\n",
    "\n",
    "  For any $h = h\\left(y\\left(x\\right)\\right)$ where $y\\in\\mathbb{R}^{n}$ and $x\\in\\mathbb{R}^{m}$,\n",
    "  \n",
    "  \\begin{align}\n",
    "    \\nabla_{x}h = \\sum_{i=1}^{n}{\\frac{\\partial h}{\\partial y_{i}}\\nabla y_{i}\\left(x\\right)}.\n",
    "  \\end{align}\n",
    "\n",
    "### 4. The graph structure of calculations and forward accumulation\n",
    "\n",
    "Forward accumulation is computing the derivative using the chain rule starting from the inner most derivative to the outer most derivative, where we assume the most basic variables have seed values. Using a graph helps visualize forward accumulation. For example,\n",
    "\n",
    "\\begin{align}\n",
    " f\\left(x,y\\right) &= \\frac{x}{y} +cos(x)sin(y)\\\\\n",
    " x &= y = 1\n",
    "\\end{align}\n",
    "\n",
    " \n",
    "![](img/graph_eg.png)\n",
    "\n",
    "| Trace | Elementary Function | Current Value | Elementary Function Derivative | &nbsp; &nbsp; $\\nabla_{x}$ Value &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp; &nbsp; $\\nabla_{y}$ Value &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "| :---: | :-----------------: | :-----------: | :----------------------------: | :-----------------: | :-----------------: | :-----------------: |\n",
    "| $w_{1}$ | $1$ | $1$ | $\\dot{w_1}$ | $1$ | $0$ |\n",
    "| $w_{2}$ | $1$ | $1$ | $\\dot{w_2}$ | $0$ | $1$ |\n",
    "| $w_{3}$ | $cos{(w_1})$ | $cos{(1)}$ | $-sin{(w_1)}\\dot{w_1}$ | $-sin(1)$ | $0$ |\n",
    "| $w_{4}$ | $sin{(w_2})$ | $sin{(1)}$ | $cos{(w_2)}\\dot{w_2}$ | $0$ | $cos{(1)}$ |\n",
    "| $w_{5}$ | $w_3\\dot w_4$ | $sin{(1)}cos{(1)}$ | $w_4\\dot{w_3} + w_3\\dot{w_4}$ | $-sin^2{(1)}$ | $cos^2{(1)}$ |\n",
    "| $w_{6}$ | $w_1 / w_2$ | $1$ | $\\dot{w_1}/w_2 - w_1 \\dot{w_2}/ w_2^2$ | $1$ | $-1$ |\n",
    "| $w_{7}$ | $w_5 + w_6$ | $sin{(1)}cos{(1)} + 1$ | $\\dot{w_5} + \\dot{w_6}$ | $-sin^2{(1)} + 1$ | $cos^2{(1)}-1$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T25yH8o1rSag"
   },
   "source": [
    "# Software Organization\n",
    "\n",
    "<img src=\"PYPI.png\">\n",
    "\n",
    " ```\n",
    " autodiff\\\n",
    "          autodiff\\\n",
    "                    __init__.py\n",
    "                    functions.py\n",
    "                    scalar.py\n",
    "                    vector.py\n",
    "          tests\\\n",
    "                    test_composite.py\n",
    "                    test_functions.py\n",
    "                    test_scalar.py \n",
    "                    test_vector.py\n",
    "          docs\\\n",
    "                    milestone1.ipynb\n",
    "                    milestone2.ipynb\n",
    "          README.md\n",
    "          requirements.txt\n",
    "          setup.cfg\n",
    "          LICENSE\n",
    "               \n",
    " ``` \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yl-jStnJqc6_"
   },
   "source": [
    "# Scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXCQ0seUqf4H"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9vbJSZQqh8C"
   },
   "source": [
    "# Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "454Wogp5qk-b"
   },
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBM5howScEBz"
   },
   "source": [
    "# Software Organization\n",
    "\n",
    " ```\n",
    " autodiff\\\n",
    "          autodiff\\\n",
    "                    __init__.py\n",
    "                    functions.py\n",
    "                    scalar.py\n",
    "                    vector.py\n",
    "          tests\\\n",
    "                    test_composite.py\n",
    "                    test_functions.py\n",
    "                    test_scalar.py \n",
    "                    test_vector.py\n",
    "          docs\\\n",
    "                    milestone1.ipynb\n",
    "                    milestone2.ipynb\n",
    "          README.md\n",
    "          requirements.txt\n",
    "          setup.cfg\n",
    "          LICENSE\n",
    "               \n",
    " ``` \n",
    " \n",
    " \n",
    " Basic modules and what they do?\n",
    "\n",
    "\n",
    "This module aims to compute forward automatic differentiation. The module we implemented can efficiently compute the derivatives of a function of automatic differentiation of a scalar input. The *scalar.py* contains the objects which compute the scalar variables returning the value and the derivative. The dunder methods add, sub, mul, truediv, pow, iadd, isub, imul, idiv, ipow are implemented in this module. The function.py contains sine,cosine,exp functions. Both scalar.py and function.py return the value and the derivative.\n",
    "\n",
    "Where do tests live? How are they run? How are they integrated? \n",
    "\n",
    "\n",
    "We are using both `TravisCI` and `Coveralls' to test our module. Each test function exists in the tests folder, and it utilizes the pytest package.\n",
    "\n",
    "   \n",
    "\n",
    "How can someone install your package? (describe how someone can download and install your package manually)\n",
    "\n",
    "  \n",
    "We are planning to release our package in `PyPI', but havent done it. Therefore, people can download our software at https://github.com/cs207FinalProjectGroup/cs207-FinalProject.git.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alKjoAWYiBeR"
   },
   "source": [
    "# Implementation Details\n",
    "\n",
    "\n",
    "We have so far implemented the *Scalar* class, which represents scalar variables. To initialize a *Scalar* class object, the user will pass in a string that represents the variable (i.e. 'x', 'y', 'x1', etc.) and the value of the variable. Additionally, the user may pass in a specific value for the derivative to begin with; if no value is specified for the derivative, then the derivative of the Scalar object defaults to $1$. The *Scalar* class holds two attributes: 1) the value of the variable `_val` at the current step and 2) a dictionary `_deriv` containing the derivative or partial derivatives (keys will be the names of the variables (i.e *x* and *y*) and the values will be the derivative value with respect to each variable).  **Should add an code block of example of instantiating Scalar object here. We should just copy this from our test code.**\n",
    "\n",
    "Storing the partial derivatives with respect to each variable allows us to easily compute additional derivatives with respect to each variable when we are performing mathematical operations because we can update each partial derivative individually. When a *Scalar* object is initialized, by default `_deriv` will just be a dictionary with the only key being the string the user passes in with value 1. A user can access the value of a *Scalar* object using the *getValue()* method and access the derivative (or partial derivatives) for the object through the *getDeriv()* method. The user can also get the derivatives/partial derivatives as a numpy array with the *getGradient()* method, which takes in a list of strings, with each element representing the variable to take the derivative with respect to, as an argument. \n",
    "\n",
    "The dunder methods __add__, __sub__, __mul__,  __truediv__, __pow__, __iadd__, __isub__, __imul__, __itruediv__, __ipow__ (and the right equivalents for the ones that have one) have been overwritten so that they return a new *Scalar* object with an updated value and derivatives. Thus, the adding or substracting two Scalars or raising a Scalar to the power of another Scalar does not change the values or derivatives of the original Scalar objects. By overwriting these methods, we are implementing forward accumulation, as the orders of operation allows us to traverse the chainrule starting from the inside.\n",
    "**Should add an code block of example of adding/substracting/pow-ing/... Scalar objects and show that the value is updated correctly and we can get the partial derivatives here. Also show that original Scalar objects are not overwritten.**\n",
    "\n",
    "We have also implemented the functions **sin**, **cos**, **tan**, **power**, and **exp**. All of these functions take in *Scalar* object and return a new *Scalar* object, thus no changes are made to the value or derivatives of the Scalar object passed in. Within these functions, the *numpy* functions *sin*, *cos*, *tan* and *exp* are used to calculate the appropriate values. <br/>\n",
    "\n",
    "The trigonometric functions  **sin(x)**, **cos(x)**, and **tan(x)** each take in a *Scalar* object *x* and apply the respective trigonometric function to the *x._val* attribute and update the derivatives accordingly.**Should add an code block of example of using the sin, cos, and tan functions.**\n",
    "\n",
    "The **power(x1, x2)** function raises *x1* to the power of *x2*. *x1* and *x2* can be any combination of *ints*, *floats*, or *Scalar* objects. If only *ints* and *floats* are provided, then *power* will throw an Exception because it is meant to be used with *Scalar* objects. If at least one *Scalar* object is provided, then **power** works just like using the **__pow__** operator and returns a new *Scalar* object without changing any values in the original *Scalar* object(s).\n",
    "**Should add an code block of example of using the power function.**\n",
    "\n",
    "Th **exp(x)** function raises *e* to the power of *x* , where *x* is a *Scalar* object. A new *Scalar* is returned with an updated value and derivative(s). \n",
    "**Should add an code block of example of using the power function.**\n",
    "\n",
    "\n",
    "\n",
    "We still need to implement the Vector class, which will be composed of Scalar objects. \n",
    "\n",
    "For now, we think that our implementation will be something like this:\n",
    "\n",
    "*Vector* will take in a list or array of *Scalar* objects. A *Vector* only has one attribute: a numpy array of *Scalar* objects, since each *Scalar* object will track its current value and derivative. The dunder methods __add__, __sub__, __mul__,  __truediv__, __pow__, __iadd__, __isub__, __imul__, __idiv__, __ipow__ (and the right equivalents) will all be overwritten so that they return a new array of *Scalar* objects with updates values and derivatives. Similar to numpy methods, the operations are conducted element-wise, i.e. In an addition operation between two *Vector* objects, the first row is added to the first row, second row is added to the second row, etc. As a result, one vector operation becomes multiple scalar operations. To access the values in the *Vector* object, the user can use the *getValue()* method, which returns a *numpy.array* of values. To access the derivatives in the *Vector* object, the user can use the *getDeriv()* method, which returns a list of dictionaries containing derivatives or partial derivatives for each *Scalar* object in the array. We can also add a function that returns this as a matrix, which is the Jacobian and add an optional argument to this function such that the user can just get the derivatives or partial derivatives with respect to the desired variables only (i.e. with respect to 'x', with respect to 'y', etc.). The user can obtain a copy of the *numpy.array* with *Scalar* objects using the *getVector()* method, which will return a copy of the *numpy.array* to the user.\n",
    "\n",
    "Likewise, for the functions that we have implemented, we have only implemented them to account for Scalars, but not Vectors, so we need to implement them to take into account Vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAYLcSGrSjMo"
   },
   "source": [
    "# Citations\n",
    "1. Sondak, David. “Automatic Differentiation: The Basics.” CS207-Lecture9. Cambridge, MA. 2 October 2018.\n",
    "\n",
    "2. Hoffman, Philipp H.W. “A Hitchhiker’s Guide to Automatic Differentiation.” *Numerical Algorithms*, 72, 24 October 2015, 775-811, *Springer Link*, DOI 10.1007/s11075-015-0067-6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--ZH1Bf4Xl75"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Presentation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
